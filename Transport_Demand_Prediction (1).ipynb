{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vncDsAP0Gaoa"
      },
      "source": [
        "# **Project Name**    -  Transport Demand prediction\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beRrZCGUAJYm"
      },
      "source": [
        "##### **Project Type**    - Regression.\n",
        "##### **Contribution**    -  Ayush Singh( Individual )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJNUwmbgGyua"
      },
      "source": [
        "# **Project Summary -**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6v_1wHtG2nS"
      },
      "source": [
        "Nairobi-Transport-Demand-Prediction dataset provided to us is in unformatted manner, uneven data, and duplicate data and also some data columns in it is irrelevant. For doing the analysis on the data, the data needs to be in correct format and well organized formed.\n",
        "\n",
        "As I read the data present in the file and gone through the details in each and every column. The data set was huge in which some of the data was not required for the analysis so the data was cleaned by dropping some unwanted columns and obtained the target variable \"number of ticket\", this is got from ride id. then created a new data frame, with the columns we required for the analysis including target variable.\n",
        "\n",
        "I used feature engineering to get useful columns out of irrelevent column.\n",
        "Each and every column were compared to gain the insights about the data by doing the exploratory data analysis using python. and also saw the distribution of target variable. Cleaning the dataset, statistically analysing the data and visualizing the data by plotting the data into different graph and charts so that the trend and relationship between the various indicators can be understand easily, Modelling and Predicting the model using Machine learning algorithms.\n",
        "\n",
        "To preform linear regression, we have to fulfil the assumption of it. so I used Variance inflation factor(VIF) and heatmap to compute multicollinearity in the dataset, I remove the features which have high multicollinearity and acquire the best features for regression. Perform train test split, feature scaling by zscore. I used different types of regression algorithm to train our model like, Linear Regression, Regularized linear regression (Ridge and Lasso), and used all the feature without checking multicollinearity to train our model like, Decision tree regressor, Random Forest regressor, and XGboost regresssor and Also I tuned the parameters of  Regularized linear regression (Ridge and Lasso), Random Forest regressor and XGboost regressor and also found the important features for training the model.\n",
        "\n",
        "Out of them XGboost with tuned hyperparameters gave the best result.\n",
        "\n",
        "This resulting model can be used by Mobiticket and bus operators to anticipate customer demand for certain rides, to manage resources and vehicles more efficiently, to offer promotions and sell other services more effectively, such as microinsurance, or even improve customer service by being able to send alerts and other useful information to customers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6K7xa23Elo4"
      },
      "source": [
        "# **GitHub Link -**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1o69JH3Eqqn"
      },
      "source": [
        "https://github.com/meyush0/Transport-Demand-Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQaldy8SH6Dl"
      },
      "source": [
        "# **Problem Statement**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpeJGUA3kjGy"
      },
      "source": [
        "#### This challenge asks you to build a model that predicts the number of seats that Mobiticket can expect to sell for each ride, i.e for a specific route on a specific date and time. There are 17 routes in this dataset. All of the routes end in Nairobi and originate in town to the North-West of the Nairobi towards Lake Victoria.\n",
        "\n",
        "#### The towns from Which these routes originate are:\n",
        "\n",
        "* Awendo\n",
        "* Homa Bay\n",
        "* Kehancha\n",
        "* Kendu Bay\n",
        "* Keroka\n",
        "* Keumbu\n",
        "* Kijauri\n",
        "* Kisii\n",
        "* Mbita\n",
        "* Migori\n",
        "* Ndhiwa\n",
        "* Nyachenge\n",
        "* Oyugis\n",
        "* Rodi\n",
        "* Rongo\n",
        "*Sirare\n",
        "\n",
        "#### the routes from these 17 origins to the first stop in the outskirts od Nairobi takes approximately 8 to 9 hours from time of departure. From the first stop in the outskirts of Nairobi into the main bus terminal, where most passengers get off, in central Business District, takes another 2 to 3 hours depending on traffic.\n",
        "\n",
        "#### The three stops that all these routes make in Nairobi (in order) are:\n",
        "\n",
        "1. Kawangware: the first stop in the outskirts of Nairobi.\n",
        "2. Westlands\n",
        "3. Afya Centre: the main bus terminal where most passengers disembark\n",
        "#### The three stops that all these routes make in Nairobi (in order) are :-\n",
        "\n",
        "1. Kawangware: the first stop in the outskirts of Nairobi\n",
        "\n",
        "2. Westlands\n",
        "\n",
        "3. Afya Centre: the main bus terminal where most passengers disembark\n",
        "\n",
        "\n",
        "#### Passengers of these bus (or shuttle) rides are affected by Nairobi traffic not only during their ride into the city, but from there they must continue their journey to their final destination in Nairobi wherever that may be Traffic can act as a deterrent for those who have the option to avoid buses that arrive in Nairobi during peak traffic hours. On the other hand, traffic may be an indication for people's movement patterns, reflecting business hours, cultural events, political events, and holidays."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_i_v8NEhb9l"
      },
      "source": [
        "# ***Let's Begin !***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhfV-JJviCcP"
      },
      "source": [
        "## ***1. Know Your Data***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3lxredqlCYt"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "outputs": [],
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RnN4peoiCZX"
      },
      "source": [
        "### Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "8pzvCcTaZhNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "outputs": [],
      "source": [
        "# Load Dataset\n",
        "data=pd.read_csv(\"/content/drive/MyDrive/ML - Capstone (Regression)/train_revised.csv\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x71ZqKXriCWQ"
      },
      "source": [
        "### Dataset First View"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "outputs": [],
      "source": [
        "# Dataset First eight values\n",
        "data.head(8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8O6G_mm-ZIcd"
      },
      "outputs": [],
      "source": [
        "# dataset last eifgt values\n",
        "data.tail(8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hBIi_osiCS2"
      },
      "source": [
        "### Dataset Rows & Columns count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "outputs": [],
      "source": [
        "# Dataset Rows & Columns count\n",
        "print('Dataset Rows: {}'.format(data.shape[0]))\n",
        "print('Dataset Columns: {}'.format(data.shape[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlHwYmJAmNHm"
      },
      "source": [
        "### Dataset Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "outputs": [],
      "source": [
        "# Dataset Info\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35m5QtbWiB9F"
      },
      "source": [
        "#### Duplicate Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "outputs": [],
      "source": [
        "# Dataset Duplicate Value Count\n",
        "data.duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoPl-ycgm1ru"
      },
      "source": [
        "#### Missing Values/Null Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "outputs": [],
      "source": [
        "# Missing Values/Null Values Count\n",
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "outputs": [],
      "source": [
        "#there is no null values in this dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0kj-8xxnORC"
      },
      "source": [
        "### What did you know about your dataset?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfoNAAC-nUe_"
      },
      "source": [
        "###### Nairobi Transport Data.csv (zipped) is the dataset of tickets *purchased from Mobiticket for the 17 routes from 'up country \" into Nairobi between 17 october 2017 and 20 April 2018. This dataset includes the variables: ride_id,seat_number,payment_method,payment_receipt,travel_date,travel_time.travel_from,travel_to,car_type,max_capacity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      },
      "source": [
        "## ***2. Understanding Your Variables***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "outputs": [],
      "source": [
        "# Dataset Columns\n",
        "print(data.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "outputs": [],
      "source": [
        "# Dataset Describe\n",
        "data.describe(include='all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHbmEwzUZIcf"
      },
      "outputs": [],
      "source": [
        "#finding the relation between car_type and max_capacity\n",
        "data.groupby(['car_type','max_capacity'])['max_capacity'].count().unstack()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLRDm72WZIcf"
      },
      "source": [
        "Bus has 49 seat capacity and shuttle had 11 seat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00BHXOoWZIcf"
      },
      "outputs": [],
      "source": [
        "#finding the relation between 'car_type' and 'travel_from'\n",
        "data.groupby(['travel_from','car_type'])['car_type'].count().unstack()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjHsKXn5ZIcf"
      },
      "source": [
        "Shuttle only used for travel from Keroka, Keumbu, Kijauri and kisii town where bus used for travel from all the town"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "del1Kq31ZIcf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBTbrJXOngz2"
      },
      "source": [
        "### Variables Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJV4KIxSnxay"
      },
      "source": [
        "`ride_id` : unique ID of the vehicle on a specific route on a specific day and time\n",
        "\n",
        "`seat_number`: seat assigned to ticket.\n",
        "\n",
        "`payment_method` :  Method used by customer to purchase ticket from Mobiticket.\n",
        "\n",
        "`payment_receipt` : unique id number for ticket purchased from Mobiticket.\n",
        "\n",
        "`travel_date` : date of ride departure. (DD/MM/YYYY)\n",
        "\n",
        "`travel_time` : Scheduled departure time of ride. (hh:mm)\n",
        "\n",
        "`travel_from` : town from which ride originated.\n",
        "\n",
        "`travel_to` : destination od ride.All rides are to Nairobi.\n",
        "\n",
        "`car_type` : vehicle type. (shuttle or bus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3PMJOP6ngxN"
      },
      "source": [
        "### Check Unique Values for each variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "outputs": [],
      "source": [
        "# Check Unique Values for each variable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8arhy7SjZIcp"
      },
      "source": [
        "***for ride_id:***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otxi_3m4ZIcp"
      },
      "outputs": [],
      "source": [
        "unique_ride_id = data['ride_id'].unique()\n",
        "print(f\"ride_id: {len(unique_ride_id)} unique values\")\n",
        "print(unique_ride_id)\n",
        "print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbIJbtwTZIcp"
      },
      "source": [
        "***for seat_number:***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5BLdKPUZIcp"
      },
      "outputs": [],
      "source": [
        "unique_seat_number = data['seat_number'].unique()\n",
        "print(f\"seat_number: {len(unique_seat_number)} unique values\")\n",
        "print(unique_seat_number)\n",
        "print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDlvBY3cZIcr"
      },
      "source": [
        "***for payment_method:***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9u6iCknZIcr"
      },
      "outputs": [],
      "source": [
        "unique_payment_method = data['payment_method'].unique()\n",
        "print(f\"payment_method: {len(unique_payment_method)} unique values\")\n",
        "print(unique_payment_method)\n",
        "print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Imx1Obt8ZIcs"
      },
      "source": [
        "***for payment_receipt:***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NN5ShoAQZIcs"
      },
      "outputs": [],
      "source": [
        "unique_payment_receipt = data['payment_receipt'].unique()\n",
        "print(f\"payment_receipt: {len(unique_payment_receipt)} unique values\")\n",
        "print(unique_payment_receipt)\n",
        "print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4g-aV3tZIcs"
      },
      "source": [
        "***for travel_date:***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oC7_C-AKZIcs"
      },
      "outputs": [],
      "source": [
        "unique_travel_date = data['travel_date'].unique()\n",
        "print(f\"travel_date: {len(unique_travel_date)} unique values\")\n",
        "print(unique_travel_date)\n",
        "print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U31Nqt7UZIcs"
      },
      "source": [
        "***for travel_time:***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T10_-V1ZZIct"
      },
      "outputs": [],
      "source": [
        "unique_travel_time = data['travel_time'].unique()\n",
        "print(f\"travel_time: {len(unique_travel_time)} unique values\")\n",
        "print(unique_travel_time)\n",
        "print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eH_AKeDpZIct"
      },
      "source": [
        "***for travel_from:***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOl-kwxOZIct"
      },
      "outputs": [],
      "source": [
        "unique_travel_from = data['travel_from'].unique()\n",
        "print(f\"travel_from: {len(unique_travel_from)} unique values\")\n",
        "print(unique_travel_from)\n",
        "print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcwIh_QyZIct"
      },
      "source": [
        "***for travel_to:***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdy9mJumZIct"
      },
      "outputs": [],
      "source": [
        "unique_travel_to = data['travel_to'].unique()\n",
        "print(f\"travel_to: {len(unique_travel_to)} unique values\")\n",
        "print(unique_travel_to)\n",
        "print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UChtry8kZIct"
      },
      "source": [
        "***for car_type:***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ty5iXS91ZIct"
      },
      "outputs": [],
      "source": [
        "unique_car_type = data['car_type'].unique()\n",
        "print(f\"car_type: {len(unique_car_type)} unique values\")\n",
        "print(unique_car_type)\n",
        "print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbEqzgfdZIct"
      },
      "source": [
        "***for max_capacity:***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9im-rorpZIcu"
      },
      "outputs": [],
      "source": [
        "unique_max_capacity = data['max_capacity'].unique()\n",
        "print(f\"max_capacity: {len(unique_max_capacity)} unique values\")\n",
        "print(unique_max_capacity)\n",
        "print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kGfmnQAZIcu"
      },
      "source": [
        "* ride_id:   Count: 6249 unique values\n",
        "\n",
        "* seat_number: Count: 61 unique values\n",
        "\n",
        "* payment_method: Unique values: ['Mpesa', 'Cash']\n",
        "\n",
        "* payment_receipt: Count: 51645 unique values\n",
        "\n",
        "* travel_date:   Count: 149 unique values\n",
        "\n",
        "* travel_time:  Count: 78 unique values\n",
        "\n",
        "* travel_from: Unique values: ['Migori', 'Keroka', 'Homa Bay', 'Kisii', 'Keumbu', 'Rongo', 'Oyugis', 'Awendo', 'Sirare', 'Nyachenge', 'Rodi', 'Ndhiwa', 'Kijauri', 'Kendu Bay', 'Kehancha', 'Mbita', 'Kisumu']\n",
        "\n",
        "* travel_to: Unique values: ['Nairobi']\n",
        "\n",
        "* car_type: Unique values: ['Bus', 'shuttle']\n",
        "\n",
        "* max_capacity: Unique values: ['49', '11']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFHV4Op_ZIcu"
      },
      "source": [
        "### ***Finding Our Target Variable***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Enhu81rEZIcu"
      },
      "source": [
        "The target variable, in this case, is the number of seats that Mobiticket can expect to sell for each ride. This is the variable you want your predictive model to estimate or predict. It represents the outcome or response that your model is trying to understand or forecast.\n",
        "\n",
        "In the context of the challenge, you'll likely have historical data that includes information on the number of seats sold for each ride."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKOUu8SXZIcu"
      },
      "outputs": [],
      "source": [
        "#apply groupby on ride_id to get number of ticket\n",
        "label=data.groupby(['ride_id']).seat_number.count().sort_values(ascending=False).rename('number_of_ticket')\n",
        "label.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruT5lXbdZIcu"
      },
      "source": [
        "Now we found our target variable so let us delete the duplicate value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibCe2V5yZIcu"
      },
      "outputs": [],
      "source": [
        "#drop duplicates\n",
        "data1=data.drop_duplicates('ride_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgKEHo8IZIcu"
      },
      "outputs": [],
      "source": [
        "data1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXjK2CxhZIcu"
      },
      "outputs": [],
      "source": [
        "#merging of target variable on the basis od ride_id\n",
        "data2=data1.merge(label,how='left',on='ride_id')\n",
        "data2.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GE2J6WTZIcv"
      },
      "source": [
        "Now we have found our final dataset so let us remove features that dosen't seem to be important for predicting the number of ticket in out model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVSam3TgZIcv"
      },
      "outputs": [],
      "source": [
        "#remove unwanted columns\n",
        "data2=data2.drop(['seat_number','payment_receipt'],axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkFFY1k_ZIcv"
      },
      "source": [
        "## ***Removing Constant Features***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcBcbfIEZIcv"
      },
      "source": [
        "We need to first remove the constant features (i.e Nairobi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6orbDLY0ZIcv"
      },
      "outputs": [],
      "source": [
        "data2 = data2.drop(\"travel_to\", axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ncfr6ehqZIcv"
      },
      "source": [
        "##  ***3. feature Enginering***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTRexV2VZIcv"
      },
      "outputs": [],
      "source": [
        "#This will result in a Series of strings representing the dates.\n",
        "travel_date=pd.to_datetime(data2['travel_date'],dayfirst=True).astype('str')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIFgAxh5ZIcv"
      },
      "outputs": [],
      "source": [
        "# single column representing the combined datetime for further analysis or modeling.\n",
        "data2['date']=travel_date  + \" \"+data2['travel_time']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSG658tYZIcw"
      },
      "outputs": [],
      "source": [
        "data2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Btbz1FwzZIcw"
      },
      "outputs": [],
      "source": [
        "def time_features (df):\n",
        "    \"\"\"This function takes dataframe as an argument and extracts the different features\n",
        "    from the date variable of the dataset and finaly\n",
        "    returns ti dataset I\"\"\"\n",
        "\n",
        "    df[\"date\"]=pd.to_datetime(df[\"date\"])\n",
        "    #Converts the 'date' column to datetime format.\n",
        "\n",
        "    df[\"day of week\"]=df[\"date\"].dt.dayofweek\n",
        "    # Extracts the day of the week.\n",
        "\n",
        "    df[\"day of year\"]=df[\"date\"].dt.dayofyear\n",
        "    #Extracts the day of the year.\n",
        "\n",
        "    df[\"day of month\"]=df[\"date\"].dt.day\n",
        "    #Extracts the day of the month.\n",
        "\n",
        "    df[\"hour\"]=df[\"date\"].dt.hour\n",
        "    #Extracts the hour.\n",
        "\n",
        "    df[\"minute\"]=df[\"date\"].dt.minute\n",
        "    # Extracts the minute.\n",
        "\n",
        "    df[\"is weekend\"] = df[\"day of week\"].apply(lambda x: 1 if x in [5, 6] else 0)\n",
        "    # Creates a binary feature indicating whether it's the weekend (Saturday or Sunday).\n",
        "\n",
        "    df[\"year\"]=df[\"date\"].dt.year\n",
        "    # Extracts the year.\n",
        "\n",
        "    df[\"quarter\"]=df[\"date\"].dt.quarter\n",
        "    #Extracts the quarter.\n",
        "\n",
        "    df[\"month\"]=df[\"date\"].dt.month\n",
        "    #Extracts the month.\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkJg7i1nZIcw"
      },
      "source": [
        "incorporating time-related features can help the model understand and leverage temporal patterns in the data. It allows the model to learn how different times of the day, week, month, or year might impact the number of seats sold for each ride."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIYrJhdlZIcw"
      },
      "outputs": [],
      "source": [
        "#calling the function\n",
        "final_data=time_features(data2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6K_2t91ZIcx"
      },
      "outputs": [],
      "source": [
        "#nrw dataframe with addition of time features\n",
        "final_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dY4EY2FzZIcx"
      },
      "outputs": [],
      "source": [
        "#for perticular car type\n",
        "dataset_bus=final_data[final_data['car_type']=='bus']\n",
        "dataset_shuttle=final_data[final_data['car_type']=='shuttle']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFWLCAWuZIcx"
      },
      "outputs": [],
      "source": [
        "dataset=(dataset_bus,dataset_shuttle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2DUKlV1ZIcx"
      },
      "outputs": [],
      "source": [
        "#car_type value\n",
        "final_data[\"car_type\"].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSa1f5Uengrz"
      },
      "source": [
        "### What all manipulations have you done and insights you found?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbyXE7I1olp8"
      },
      "source": [
        "1. Identified 17 routes originating from towns to the North-West    of Nairobi towards Lake Victoria.\n",
        "2. Noted that the travel duration from origins to the first stop    in the outskirts of Nairobi takes 8 to 9 hours.\n",
        "3. Identified the three stops in Nairobi for all routes:            Kawangware, Westlands, and Afya Centre.\n",
        "4. Created a target variable, 'number_of_ticket,' representing      the count of seats for each ride.\n",
        "5. Extracted various time-related features from the 'date'          column using the `time_features` function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF8Ens_Soomf"
      },
      "source": [
        "## ***4. Univariate Analysis***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wOQAZs5pc--"
      },
      "source": [
        "#### Chart - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "outputs": [],
      "source": [
        "\n",
        "sns.set(style=\"darkgrid\")\n",
        "\n",
        "# Plot the distribution of 'number_of_ticket'\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(final_data['number_of_ticket'], bins=30, kde=True, color='skyblue')\n",
        "plt.title('Distribution of Number of Tickets')\n",
        "plt.xlabel('Number of Tickets')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5QZ13OEpz2H"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XESiWehPqBRc"
      },
      "source": [
        "A histogram is suitable for visualizing the distribution of a continuous variable, such as the count of tickets `number_of_ticket`. The bins provide insights into the frequency distribution and potential patterns in ticket sales."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_j1G7yiqdRP"
      },
      "source": [
        "The histogram shows that the majority of rides have a relatively low count of tickets sold. This suggests that most rides may not be fully occupied, but there are a few instances with a higher number of tickets sold."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "448CDAPjqfQr"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cspy4FjqxJW"
      },
      "source": [
        "Understanding the distribution of ticket sales `('number_of_ticket')` can help in optimizing resource allocation, such as adjusting the number of available seats based on historical demand patterns. This ensures that resources are efficiently utilized."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSlN3yHqYklG"
      },
      "source": [
        "#### Chart - 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "outputs": [],
      "source": [
        "# Plot the distribution of 'day of week'\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(x='day of week', data=final_data, palette='viridis')\n",
        "plt.title('Distribution of Day of Week')\n",
        "plt.xlabel('Day of Week')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6dVpIINYklI"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aaW0BYyYklI"
      },
      "source": [
        "A countplot is effective for visualizing the distribution of categorical variables. In this case, we're exploring the distribution of rides across different days of the week. The countplot provides a clear count of occurrences for each day."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijmpgYnKYklI"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSx9atu2YklI"
      },
      "source": [
        "The countplot reveals the distribution of rides across different days of the week. It appears that there is variability in the number of rides on different days. Further analysis may be needed to understand the factors contributing to these variations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JiQyfWJYklI"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcBbebzrYklV"
      },
      "source": [
        "If certain days with low demand still incur high operational costs, it could result in financial challenges. For example, if the business operates at a loss on specific days due to high fixed costs, it may raise concerns about sustainability."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EM7whBJCYoAo"
      },
      "source": [
        "#### Chart - 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6GMdE67YoAp",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Plot the distribution of 'hour'\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(x='hour', data=final_data, palette='plasma')\n",
        "plt.title('Distribution of Hour')\n",
        "plt.xlabel('Hour')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fge-S5ZAYoAp"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dBItgRVYoAp"
      },
      "source": [
        "Similar to `'day of week'`, we're interested in the distribution of rides across different hours of the day. A countplot helps visualize the frequency of rides at each hour."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85gYPyotYoAp"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jstXR6OYoAp"
      },
      "source": [
        "The countplot for hours shows the distribution of rides across different hours of the day. There might be peaks during certain hours, indicating times of higher demand for rides. This could be associated with peak commuting times or other factors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoGjAbkUYoAp"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      },
      "source": [
        "If the countplot for 'hour' reveals consistently low demand during peak commuting hours or other historically high-demand periods, it could lead to negative growth. Low utilization during peak times might indicate missed revenue opportunities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Of9eVA-YrdM"
      },
      "source": [
        "#### Chart - 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xb1gnmx-ZIc2"
      },
      "outputs": [],
      "source": [
        "#relevent column for histogram\n",
        "plot_col=['number_of_ticket','travel_time','day of month', 'day of week',\"month\"]\n",
        "#convert travel time unit into hour.\n",
        "final_data[\"travel_time\"] = final_data[\"travel_time\"].str.split(':').apply(lambda x: int(x[0]) + int(x[1])/60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6FLmTdoZIc2"
      },
      "outputs": [],
      "source": [
        "final_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irlUoxc8YrdO",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "#histogram\n",
        "for col in plot_col[0:]:\n",
        "    fig = plt.figure(figsize=(9, 6))\n",
        "    ax = fig.gca()\n",
        "    feature = final_data[col]\n",
        "    feature.hist(bins=50, ax = ax)\n",
        "    ax.axvline(feature.mean(), color='magenta', linestyle='dashed', linewidth=2)\n",
        "    ax.axvline(feature.median(), color='cyan', linestyle='dashed', linewidth=2)\n",
        "    ax.set_title(col)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iky9q4vBYrdO"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJRCwT6DYrdO"
      },
      "source": [
        "Overlaying vertical lines for mean and median allows for an easy comparison between the two measures of central tendency. This is useful for understanding the shape of the distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6T5p64dYrdO"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      },
      "source": [
        "* if mean > median > mode then, distribution of the data is positively skewed,\n",
        "* if mean = median = mode then, no skewed that is normally distributed,\n",
        "\n",
        "otherwise, it is negatively skewed.\n",
        "There is a positive skewed in `number_of_ticket`, `ticket_time` & `month` and `day_of_month` and approximately no skewed in `day_of_week`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-Ehk30pYrdP"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLNxxz7MYrdP"
      },
      "source": [
        " Histograms help in identifying patterns and trends in your data. This could reveal seasonality, trends over time, or patterns in customer behavior. Understanding these patterns allows for better strategic planning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfNujRFwZIc3"
      },
      "source": [
        "### chart Box plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMFe19bVZIc3"
      },
      "outputs": [],
      "source": [
        "#boxplot\n",
        "plt.figure(figsize=(12,10))\n",
        "for x,y in zip(range(1,len(plot_col)+1),plot_col):\n",
        "    plt.subplot(2,3,x)\n",
        "    plt.boxplot(final_data[y],patch_artist=True,notch=True)\n",
        "    plt.xlabel(y,fontsize=16)\n",
        "#plt.title(\"Time series on cyber crime in State/UT\",fontsize=25)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-i5CPyHbZIc4"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXXSmUgiZIc5"
      },
      "source": [
        "This chart(Box-Plot) help us to understand the outliars in the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7y7Z17AZIc6"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGtfQmczZIc6"
      },
      "source": [
        "from Boxplot, we have got to know about outliers, as we see that, `day_of_month`, `day_of_week`, `month` have no outlier, but `travel_time` and `number_of_ticket` have a lot of outliers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQJvtOl-ZIc6"
      },
      "source": [
        "## ***5. Bivariate Analysis***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8Mh-J0KZIc6"
      },
      "source": [
        "###### Travel from different cars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXjgZFcNZIc6"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(18, 12))\n",
        "\n",
        "ax = sns.countplot(x=final_data['travel_from'], hue=final_data[\"car_type\"], palette=\"Set3\")\n",
        "\n",
        "plt.title(\"Travel from Different Cars\")\n",
        "\n",
        "for p in ax.patches:\n",
        "    if p.get_height() > 0:\n",
        "        ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2, p.get_height()), ha=\"center\", size=9)\n",
        "\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcxuIMRPYuh3"
      },
      "source": [
        "The chart compares the counts of different categories `('travel_from')` for each car type. It's effective when you want to visualize and compare the distribution of categorical data across different groups."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwzvFGzlYuh3"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyqkiB8YYuh3"
      },
      "source": [
        "2499 and 521 peoples are travel by bus and shuttle respectively from kisii between 17-10-17 and 20-04-18 which is maximum among all town"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OH-pJp9IphqM"
      },
      "source": [
        "#### Chart - Box-plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "outputs": [],
      "source": [
        "final_data.describe(include=['object']).columns.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUGDpZDrZIc7"
      },
      "outputs": [],
      "source": [
        "categorical_features=['payment_method','travel_from','car_type']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Hya1qs7ZIc7"
      },
      "outputs": [],
      "source": [
        "#plot a boxplot fot the label by each categorical features\n",
        "\n",
        "for col in categorical_features:\n",
        "    fig=plt.figure(figsize=(9,6))\n",
        "    ax=fig.gca()\n",
        "    final_data.boxplot(column='number_of_ticket',by=col,ax=ax)\n",
        "    ax.set_title('Label by'+col)\n",
        "    ax.set_ylabel('Number of Ticket')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbFf2-_FphqN"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loh7H2nzphqN"
      },
      "source": [
        "The \"whiskers\" in a boxplot show the spread of the data, giving you an idea of how much variation exists within each category."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIIx-8_IphqN"
      },
      "source": [
        "### Check Multicollinearity**\n",
        "\n",
        "The goal is to ensure that the features used in your model are not highly correlated, as this can lead to unstable coefficient estimates and challenges in interpretation. By iteratively checking and adjusting for multicollinearity, you aim to improve the robustness of your regression model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "outputs": [],
      "source": [
        "#heatmap\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.heatmap(final_data.corr(),annot=True,cmap=\"Greens\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pq2ys8WrZIc8"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZDQ0O1TZIc8"
      },
      "source": [
        "There is a prefect positive correlation between\n",
        "\n",
        "1. day_of_year & month,\n",
        "\n",
        "2. hour and travel_time.\n",
        "\n",
        "There is a high positive correlation between\n",
        "\n",
        "1. day_of_year and quarter,\n",
        "\n",
        "2. quarter and month.\n",
        "\n",
        "There is a high negative correlation between\n",
        "\n",
        "1. quarter and year,\n",
        "\n",
        "2. month and year,\n",
        "\n",
        "3. year and day_of_year."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylIVtMebZIc8"
      },
      "outputs": [],
      "source": [
        "#all numerical feature except target variable\n",
        "col=set(final_data.describe().columns.values)-{'number_of_ticket'}\n",
        "col"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vYk7dPcZIc8"
      },
      "outputs": [],
      "source": [
        "#Multicollinearity by VIF\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "def calculate_vif(x):\n",
        "\n",
        "    #vif\n",
        "    vif=pd.DataFrame()\n",
        "    vif['variables']=x.columns\n",
        "    vif['VIF']=[variance_inflation_factor(x.values, i) for i in range(x.shape[1])]\n",
        "\n",
        "    return(vif)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZDcIjp2ZIc9"
      },
      "outputs": [],
      "source": [
        "calculate_vif(final_data[[i for i in col]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVpBkb1tZIc9"
      },
      "outputs": [],
      "source": [
        "# Exclude specific variables from col\n",
        "selected_columns = [i for i in col if i not in [\"travel_time\", \"day of year\", \"quarter\", \"year\",\"ride_id\",\"max_capacity\"]]\n",
        "\n",
        "# Calculate VIF\n",
        "vif_result_subset =calculate_vif(final_data[selected_columns])\n",
        "\n",
        "# Display the VIF DataFrame for the subset\n",
        "print(vif_result_subset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wr1TJp2ZIc9"
      },
      "source": [
        "The second set of VIF results showed that the remaining features have more reasonable levels of correlation with each other."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZMv9y9UZIc9"
      },
      "outputs": [],
      "source": [
        "#required independent features\n",
        "req_features=calculate_vif(final_data[[i for i in col if i not in ['travel_time',\"day of year\",\"quarter\",\"year\",'ride_id','max_capacity']]]).variables.values\n",
        "req_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cpTrYpeZIc9"
      },
      "source": [
        " `(req_features)` with acceptable VIF values for further analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZR9WyysphqO"
      },
      "source": [
        "#### Chart -  countplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "outputs": [],
      "source": [
        "last_date=final_data[\"date\"].max()\n",
        "first_date=final_data[\"date\"].min()\n",
        "print(f\"dataset have data between {first_date} and {last_date}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofUjVIjKZIc9"
      },
      "outputs": [],
      "source": [
        "#function for plotting countplot with values on their top.\n",
        "def countplot_values(feature):\n",
        "    y = final_data[feature].value_counts().reset_index()[feature]\n",
        "\n",
        "    # Bar plot\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    final_data[feature].value_counts().plot(kind='barh', color=\"orange\")\n",
        "\n",
        "    # Adding count values on the bars\n",
        "    for index, value in enumerate(y):\n",
        "        plt.text(value, index, str(value), ha='left', va='center', fontsize=10)\n",
        "\n",
        "    # Display the plot\n",
        "    plt.show()\n",
        "\n",
        "    return feature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBWh0ZCeZIc9"
      },
      "source": [
        "### Payment Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyvYZJl_ZIc9"
      },
      "outputs": [],
      "source": [
        "countplot_values(\"payment_method\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqVkqIYuZIc-"
      },
      "source": [
        "Mpesa is used mostly in Payment mode type, i.e., cash is less prefered by the people who travel to Nairobi."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2_wwiV_ZIc-"
      },
      "source": [
        "### car type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M81CVwGJZIc-"
      },
      "outputs": [],
      "source": [
        "countplot_values('car_type')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYojVkd2ZIc-"
      },
      "source": [
        "Mostly people travel by a bus (i.e. with maximum capacity 49) as compare to shuttle (whose maximum capacity is 11)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgIOctICZIc_"
      },
      "source": [
        "###  Travel time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0R3pRt-ZIc_"
      },
      "outputs": [],
      "source": [
        "countplot_values('travel_time')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhl9od8LZIc_"
      },
      "source": [
        "Most prefer time for travel to Nairobi is 7:04 A.M., 7:08 A.M. and 7:06 A.M. because most vehicle are began at 7:04 A.M., 7:08 A.M. and 7:06 A.M. for travel to Nairobi."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0mospOgZIc_"
      },
      "source": [
        "### Travel from"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9e4Wt3iBZIc_"
      },
      "outputs": [],
      "source": [
        "countplot_values('quarter')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXsBUn9wZIc_"
      },
      "source": [
        "Mostly vehicle are originated from Kisii, Rongo and Kijauri."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5RzdmFhZIc_"
      },
      "source": [
        "### Quarter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPCgkY2nZIdA"
      },
      "outputs": [],
      "source": [
        "countplot_values('quarter')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIkTgfpjZIdA"
      },
      "source": [
        "we conclude that maximum vehicles are used in quarter 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Bldbo60ZIdA"
      },
      "source": [
        "### year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4zCRW7AZIdA"
      },
      "outputs": [],
      "source": [
        "countplot_values('year')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DApSWYzbZIdA"
      },
      "source": [
        "This dataset contains data of 2 year.(i.e. 2017 and 2018)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZoRl9eIZIdA"
      },
      "source": [
        "### Month"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iY5oIX7ZIdB"
      },
      "outputs": [],
      "source": [
        "countplot_values('month')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6yCfd6qZIdB"
      },
      "source": [
        "we conclude that maximum vehicles are used in month 2, 12 and 3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jj7wYXLtphqO"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ob8u6rCTphqO"
      },
      "source": [
        "Countplot is a suitable choice when dealing with categorical data, providing a clear visual representation of the frequency distribution of each category. It's effective for analyzing the distribution of discrete variables, such as the number of tickets or counts in different categories."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZrbJ2SmphqO"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZtgC_hjphqO"
      },
      "source": [
        "* By Bus, Number of ticket 1 is most frequent with value 699.\n",
        "\n",
        "* By shuttle, Number of ticket 1 and 11 are most frequent with values 759 and 748 respectively.\n",
        "\n",
        "* Mpesa is used mostly in Payment mode type, i.e., cash is less prefered by the people who travel to Nairobi.\n",
        "\n",
        "* Mostly people travel by a bus (i.e. with maximum capacity 49) as compare to shuttle (whose maximum capacity is 11).\n",
        "\n",
        "* Mostly vehicle are originated from Kisii, Rongo and Kijauri.\n",
        "\n",
        "* Most prefer time for travel to Nairobi is 7:04 A.M., 7:08 A.M. and 7:06 A.M..\n",
        "\n",
        "* This dataset contains data of 2 year (i.e. 2017 and 2018).\n",
        "\n",
        "* we conclude that maximum vehicles are used in quarter 1.\n",
        "\n",
        "* we conclude that maximum vehicles are used in month 2, 12 and 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q29F0dvdveiT"
      },
      "source": [
        "#### Chart  - Pair Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "outputs": [],
      "source": [
        "# Select relevant features\n",
        "pairplot_features = ['number_of_ticket', 'day of week', 'hour', 'max_capacity', 'month']\n",
        "\n",
        "# Subset the data\n",
        "pairplot_data = final_data[pairplot_features]\n",
        "\n",
        "# Create a pair plot\n",
        "sns.pairplot(pairplot_data)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXh0U9oCveiU"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMmPjTByveiU"
      },
      "source": [
        "It allows us to visualize the relationships between pairs of variables. Each subplot in the grid represents the scatterplot between two variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      },
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yEUt7NnHlrM"
      },
      "source": [
        "### Statement 1: The choice of payment method is independent of the vehicle type."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      },
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HI9ZP0laH0D-"
      },
      "source": [
        "`Null Hypothesis (H0)`: Payment method and vehicle type are independent.\n",
        "\n",
        "`Alternative Hypothesis (H1)`: Payment method and vehicle type are dependent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I79__PHVH19G"
      },
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "outputs": [],
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "import pandas as pd\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Create a contingency table\n",
        "contingency_table = pd.crosstab(data['payment_method'],data['car_type'])\n",
        "\n",
        "# Perform chi-square test\n",
        "chi2, p, _, _ = chi2_contingency(contingency_table)\n",
        "\n",
        "# Print results\n",
        "print(f\"Chi-square statistic: {chi2}\")\n",
        "print(f\"P-value: {p}\")\n",
        "\n",
        "# Make a decision\n",
        "alpha = 0.05\n",
        "if p < alpha:\n",
        "    print(\"Reject the null hypothesis. Payment method and vehicle type are dependent.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. Payment method and vehicle type are independent.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ou-I18pAyIpj"
      },
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2U0kk00ygSB"
      },
      "source": [
        "I've done Chi-Square test to obtain the p-value and the `P-value=7.706172964476798e-07`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fF3858GYyt-u"
      },
      "source": [
        "##### Why did you choose the specific statistical test?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HO4K0gP5y3B4"
      },
      "source": [
        "Chi-square tests are commonly used to assess the independence between two categorical variables. The obtained p-value helps you make decisions about the null hypothesiswhether to reject it or not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_0_7-oCpUZd"
      },
      "source": [
        "### Statement 2: The distribution of travel times is the same for buses and shuttles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwyV_J3ipUZe"
      },
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      },
      "source": [
        "`Null Hypothesis (H0)`: The distribution of travel times is the same for buses and shuttles.\n",
        "\n",
        "`Alternative Hypothesis (H1)`: The distribution of travel times is different for buses and shuttles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yB-zSqbpUZe"
      },
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2do_V7W3ZIdG"
      },
      "outputs": [],
      "source": [
        "#performed test for p-value\n",
        "from scipy.stats import ks_2samp\n",
        "\n",
        "# Assuming df is your DataFrame with columns 'travel_time' and 'car_type'\n",
        "bus_travel_times = data[data['car_type'] == 'Bus']['travel_time']\n",
        "shuttle_travel_times = data[data['car_type'] == 'shuttle']['travel_time']\n",
        "\n",
        "# Perform the Kolmogorov-Smirnov test\n",
        "ks_statistic, p_value = ks_2samp(bus_travel_times, shuttle_travel_times)\n",
        "\n",
        "# Print the results\n",
        "print(f\"KS Statistic: {ks_statistic}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Decide whether to reject the null hypothesis\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis. The distribution of travel times is different for buses and shuttles.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. There is no significant difference in the distribution of travel times.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEUvejAfpUZe"
      },
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLDrPz7HpUZf"
      },
      "source": [
        "The Kolmogorov-Smirnov test is a non-parametric test that checks if two samples are drawn from the same distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49K5P_iCpZyH"
      },
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gWI5rT9pZyH"
      },
      "source": [
        "`Null Hypothesis (H0)`: There is no significant difference in the number of tickets purchased between weekdays and weekends.\n",
        "\n",
        "`Alternative Hypothesis (H1)`: There is a significant difference in the number of tickets purchased between weekdays and weekends."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nff-vKELpZyI"
      },
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "outputs": [],
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# Separate the data for weekdays and weekends\n",
        "weekday_data = final_data[final_data['is weekend'] == 0]['number_of_ticket']\n",
        "weekend_data = final_data[final_data['is weekend'] == 1]['number_of_ticket']\n",
        "\n",
        "# Perform t-test\n",
        "statistic, p_value = ttest_ind(weekday_data, weekend_data, equal_var=False)\n",
        "\n",
        "# Print the results\n",
        "print(\"T-statistic:\", statistic)\n",
        "\n",
        "# Interpret the results\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis. There is a significant difference.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. There is no significant difference.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# t-test is a statistical test used to compare the means of two groups and assess whether there is a significant difference between them."
      ],
      "metadata": {
        "id": "rq49PyOSAYYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLW572S8pZyI"
      },
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytWJ8v15pZyI"
      },
      "source": [
        "I used t-test to obtain the p-value which is `0.07045550409414393`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWbDXHzopZyI"
      },
      "source": [
        "##### Why did you choose the specific statistical test?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M99G98V6pZyI"
      },
      "source": [
        "because the column `is weeknd` is normally distributed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLjJCtPM0KBk"
      },
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiyOF9F70UgQ"
      },
      "source": [
        "### 1. Handling Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "outputs": [],
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "final_data.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89xtkJwZ18nB"
      },
      "source": [
        "### 2. Categorical Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "outputs": [],
      "source": [
        "# Encode your categorical columns\n",
        "dj= pd.get_dummies(final_data, columns=['travel_from'])\n",
        "label_enc = {'Bus':1,'shuttle':0 ,\"Mpesa\":1,\"Cash\":0}\n",
        "dj.replace(label_enc,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAYUkQziZIdL"
      },
      "outputs": [],
      "source": [
        "dj.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67NQN5KX2AMe"
      },
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDaue5h32n_G"
      },
      "source": [
        "Label Encoding for Binary Features:\n",
        "\n",
        "Features: `'car_type'`, `'payment_method'`\n",
        "* Reason: These features have only two unique values, so label encoding is suitable to convert them into numerical form (0 or 1).\n",
        "\n",
        "One-Hot Encoding for Nominal Categorical Features:\n",
        "\n",
        "Features: `'travel_from'`\n",
        "* Reason: 'travel_from' has more than two categories, and one-hot encoding helps create binary columns for each category, avoiding ordinal assumptions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNVZ9zx19K6k"
      },
      "source": [
        "### 3. Data Transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbyh00hmZIdM"
      },
      "outputs": [],
      "source": [
        "dj.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "outputs": [],
      "source": [
        "# Transform Your data\n",
        "unreqd_col=['travel_time',\"day of year\",\"quarter\",\"year\",\"ride_id\",\"travel_date\",\"max_capacity\",\"date\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfl_myF_ZIdM"
      },
      "outputs": [],
      "source": [
        "#make a new dataframe with dependent and dependent features\n",
        "df=dj.drop(columns=unreqd_col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZSNp2ttZIdM"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7slMCdFHZIdM"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhH2vgX9EjGr"
      },
      "source": [
        "### 4. Data Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "outputs": [],
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "#import libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error,r2_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s86HAhx7ZIdN"
      },
      "outputs": [],
      "source": [
        "#independent and dependent features\n",
        "y=df.iloc[:,2]  # target variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rNtxOIPRZIdN"
      },
      "outputs": [],
      "source": [
        "X=df.drop(columns=['number_of_ticket'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jo8pE6DiZIdN"
      },
      "outputs": [],
      "source": [
        "# apply zscore for scaling\n",
        "from scipy.stats import zscore\n",
        "X=X.apply(zscore)\n",
        "X.head()           #Standardizing features helps in comparing the importance of different predictors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4WIEkUgZIdN"
      },
      "outputs": [],
      "source": [
        "#train test split\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X,y,test_size=0.20, random_state=42)\n",
        "print(X_train1.shape)\n",
        "print(X_test1.shape)\n",
        "print(y_train1.shape)\n",
        "print(y_test1.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfCC591jGiD4"
      },
      "source": [
        "## ***7. ML Model Implementation***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      },
      "source": [
        "### ML Model - Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lr3gh5tVZIdO"
      },
      "outputs": [],
      "source": [
        "#import the libraryes\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "outputs": [],
      "source": [
        "# ML Model - 1 Implementation\n",
        "model1=LinearRegression()\n",
        "# Fit the Algorithm\n",
        "model1.fit(X_train1 , y_train1)\n",
        "# Predict on the model\n",
        "y_pred=model1.predict(X_test1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JHDh5XPZIdO"
      },
      "outputs": [],
      "source": [
        "#model score\n",
        "train_acc=model1.score(X_train1,y_train1)\n",
        "print('Training Accuracy :',train_acc)\n",
        "\n",
        "test_acc=model1.score(X_test1,y_test1)\n",
        "print('testing Accuracy :',test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArJBuiUVfxKd"
      },
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "outputs": [],
      "source": [
        "MSE=mean_squared_error(y_test1,y_pred)\n",
        "print('MSE is:',MSE)\n",
        "MAE=mean_absolute_error(y_test1,y_pred)\n",
        "print('MAE is:',MAE)\n",
        "r2=r2_score(y_test1,y_pred)\n",
        "print('r2:',r2)\n",
        "adjusted_r2=(1-(1-r2_score(y_test1, y_pred))*((X_test1.shape[0]-1)/(X_test1.shape[0]-X_test1.shape[1]-1)))\n",
        "print('adjust_r2 is:',adjusted_r2)\n",
        "RMSE=math.sqrt(mean_squared_error(y_test1, y_pred))\n",
        "print('RMSE is:',RMSE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      },
      "source": [
        "### ML Model - Lasso Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gm1l3ZSZIdP"
      },
      "outputs": [],
      "source": [
        "#importing Lasso\n",
        "from sklearn.linear_model import Lasso\n",
        "# ML Model - Lasso Regression Implementation\n",
        "lasso=Lasso(alpha=0.01, max_iter=4000)\n",
        "# Fit the Algorithm\n",
        "lasso.fit(X_train1 , y_train1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qY91j4m7ZIdQ"
      },
      "outputs": [],
      "source": [
        "# Predict on the model\n",
        "y_pred_l=lasso.predict(X_test1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_-FHqA6ZIdQ"
      },
      "outputs": [],
      "source": [
        "# Model score on Train and Test\n",
        "train_model_llr = lasso.score(X_train1,y_train1)\n",
        "print('Training Accuracy:',train_model_llr)\n",
        "\n",
        "test_model_llr = lasso.score(X_test1,y_test1)\n",
        "print('Testing Accuracy:',test_model_llr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWYfwnehpsJ1"
      },
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "outputs": [],
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "MSE=mean_squared_error(y_test1,y_pred_l)\n",
        "print('MSE is:',MSE)\n",
        "MAE=mean_absolute_error(y_test1,y_pred_l)\n",
        "print('MAE is:',MAE)\n",
        "r2=r2_score(y_test1,y_pred_l)\n",
        "print('r2:',r2)\n",
        "adjusted_r2=(1-(1-r2_score(y_test1, y_pred_l))*((X_test1.shape[0]-1)/(X_test1.shape[0]-X_test1.shape[1]-1)))\n",
        "print('adjust_r2 is:',adjusted_r2)\n",
        "RMSE=math.sqrt(mean_squared_error(y_test1, y_pred_l))\n",
        "print('RMSE is:',RMSE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      },
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning for lasso Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dn0EOfS6psJ2",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# ML Model - Lasso Regression Implementation with hyperparameter optimization techniques\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Fit the Algorithm\n",
        "parameters = {'alpha': [1e-15,1e-13,1e-10,1e-8,1e-5,1e-4,1e-3,\n",
        "                        1e-2,1e-1,1,5,10,20,30,40,45,50,55,60,100]}\n",
        "lasso_regressor = GridSearchCV(lasso, parameters, cv=3)\n",
        "lasso_regressor.fit(X_train1, y_train1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzHHj31eZIdR"
      },
      "outputs": [],
      "source": [
        "print(\"The best fit alpha value is found out to be :\" ,lasso_regressor.best_params_)\n",
        "print(\"\\nUsing \",lasso_regressor.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-NRHCzYZIdS"
      },
      "outputs": [],
      "source": [
        "# Predict on the model\n",
        "y_pred_lasso = lasso_regressor.predict(X_test1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWAGz4EhZIdS"
      },
      "outputs": [],
      "source": [
        "# Model score on Train and Test\n",
        "train_model_lrh = lasso_regressor.score(X_train1,y_train1)\n",
        "print('Training Accuracy:',train_model_lrh)\n",
        "\n",
        "test_model_lrh = lasso_regressor.score(X_test1,y_test1)\n",
        "print('Testing Accuracy:',test_model_lrh)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1rkdQXbZIdS"
      },
      "outputs": [],
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "MSE=mean_squared_error(y_test1,y_pred_lasso)\n",
        "print('MSE is:',MSE)\n",
        "MAE=mean_absolute_error(y_test1,y_pred_lasso)\n",
        "print('MAE is:',MAE)\n",
        "r2=r2_score(y_test1,y_pred_lasso)\n",
        "print('r2:',r2)\n",
        "adjusted_r2=(1-(1-r2_score(y_test1, y_pred_lasso))*((X_test1.shape[0]-1)/(X_test1.shape[0]-X_test1.shape[1]-1)))\n",
        "print('adjust_r2 is:',adjusted_r2)\n",
        "RMSE=math.sqrt(mean_squared_error(y_test1, y_pred_lasso))\n",
        "print('RMSE is:',RMSE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAih1iBOpsJ2"
      },
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      },
      "source": [
        "Lasso Regression is a type of linear regression that includes an L1 regularization term. The regularization strength (alpha) was optimized using GridSearchCV.\n",
        "The best alpha value chosen by GridSearchCV was not explicitly provided, but the testing accuracy improved to 0.418 after hyperparameter tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfCXol4IZIdT"
      },
      "source": [
        "### ML Model - Ridge Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6l_DZCVbZIdT"
      },
      "outputs": [],
      "source": [
        "#import redge regression\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "#lasso implimentation\n",
        "ridge = Ridge(alpha=100)\n",
        "\n",
        "#fitting the model\n",
        "ridge.fit(X_train1,y_train1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYMWTtqLZIdT"
      },
      "outputs": [],
      "source": [
        "#Model Prediction\n",
        "y_pred_rr = ridge.predict(X_test1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W47FQclEZIdU"
      },
      "outputs": [],
      "source": [
        "# Model score on Train and Test\n",
        "train_model_rr = ridge.score(X_train1,y_train1)\n",
        "print('Training Accuracy:',train_model_rr)\n",
        "\n",
        "test_model_rr = ridge.score(X_test1,y_test1)\n",
        "print('Testing Accuracy:',test_model_rr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e9C3x5QZIdU"
      },
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0z3g4HYZIdV"
      },
      "outputs": [],
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "MSE=mean_squared_error(y_test1,y_pred_rr)\n",
        "print('MSE is:',MSE)\n",
        "MAE=mean_absolute_error(y_test1,y_pred_rr)\n",
        "print('MAE is:',MAE)\n",
        "r2=r2_score(y_test1,y_pred_rr)\n",
        "print('r2:',r2)\n",
        "adjusted_r2=(1-(1-r2_score(y_test1, y_pred_rr))*((X_test1.shape[0]-1)/(X_test1.shape[0]-X_test1.shape[1]-1)))\n",
        "print('adjust_r2 is:',adjusted_r2)\n",
        "RMSE=math.sqrt(mean_squared_error(y_test1, y_pred_rr))\n",
        "print('RMSE is:',RMSE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNMIhN23ZIdV"
      },
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5ULt6o6ZIdV"
      },
      "outputs": [],
      "source": [
        "parameters = {'alpha': [1e-15,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1,2,3,4,5,10,20,30,40,45,50,55,60,100]}\n",
        "ridge_regressor = GridSearchCV(ridge, parameters, cv=3)\n",
        "ridge_regressor.fit(X_train1,y_train1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avDprdJZZIdV"
      },
      "outputs": [],
      "source": [
        "print(\"The best fit alpha value is found out to be :\" ,ridge_regressor.best_params_)\n",
        "print(\"\\nUsing \",ridge_regressor.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CITfHK7wZIdW"
      },
      "outputs": [],
      "source": [
        "#Model Prediction\n",
        "y_pred_ridge = ridge_regressor.predict(X_test1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjvVWdWIZIdW"
      },
      "outputs": [],
      "source": [
        "# Model score on Train and Test\n",
        "train_model_rrh = ridge_regressor.score(X_train1,y_train1)\n",
        "print('Training Accuracy:',train_model_rrh)\n",
        "\n",
        "test_model_rrh = ridge_regressor.score(X_test1,y_test1)\n",
        "print('Testing Accuracy:',test_model_rrh)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYHh4DXGZIdW"
      },
      "outputs": [],
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "MSE=mean_squared_error(y_test1,y_pred_ridge)\n",
        "print('MSE is:',MSE)\n",
        "MAE=mean_absolute_error(y_test1,y_pred_ridge)\n",
        "print('MAE is:',MAE)\n",
        "r2=r2_score(y_test1,y_pred_ridge)\n",
        "print('r2:',r2)\n",
        "adjusted_r2=(1-(1-r2_score(y_test1, y_pred_ridge))*((X_test1.shape[0]-1)/(X_test1.shape[0]-X_test1.shape[1]-1)))\n",
        "print('adjust_r2 is:',adjusted_r2)\n",
        "RMSE=math.sqrt(mean_squared_error(y_test1, y_pred_ridge))\n",
        "print('RMSE is:',RMSE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GllzDhC0ZIdW"
      },
      "source": [
        "### ML Model - Elastic Net Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "outputs": [],
      "source": [
        "#importing library\n",
        "from sklearn.linear_model import ElasticNet\n",
        "# ML Model - 3 Implementation\n",
        "elasticnet=ElasticNet(alpha=0.1,l1_ratio=0.7)\n",
        "# Fit the Algorithm\n",
        "elasticnet.fit(X_train1 , y_train1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "weN8s2-EZIdX"
      },
      "outputs": [],
      "source": [
        "# Predict on the model\n",
        "y_pred_en = elasticnet.predict(X_test1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXyiMiWnZIdX"
      },
      "outputs": [],
      "source": [
        "# Model score on Train and Test\n",
        "train_model_en = elasticnet.score(X_train1,y_train1)\n",
        "print('Training Accuracy:',train_model_en)\n",
        "\n",
        "test_model_en = elasticnet.score(X_test1,y_test1)\n",
        "print('Testing Accuracy:',test_model_en)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AN1z2sKpx6M"
      },
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "outputs": [],
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "MSE=mean_squared_error(y_test1,y_pred_en)\n",
        "print('MSE is:',MSE)\n",
        "MAE=mean_absolute_error(y_test1,y_pred_en)\n",
        "print('MAE is:',MAE)\n",
        "r2=r2_score(y_test1,y_pred_en)\n",
        "print('r2:',r2)\n",
        "adjusted_r2=(1-(1-r2_score(y_test1, y_pred_en))*((X_test1.shape[0]-1)/(X_test1.shape[0]-X_test1.shape[1]-1)))\n",
        "print('adjust_r2 is:',adjusted_r2)\n",
        "RMSE=math.sqrt(mean_squared_error(y_test1, y_pred_en))\n",
        "print('RMSE is:',RMSE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PIHJqyupx6M"
      },
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "outputs": [],
      "source": [
        "# ML Model - Elastic net regressor with hyperparameter optimization techniques\n",
        "parameters = {'alpha': [1e-15,1e-13,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1e-1,1,5,10,20,30,40,45,50,55,60,100],\n",
        "              'l1_ratio':[0.3,0.4,0.5,0.6,0.7,0.8]}\n",
        "elastic_regressor = GridSearchCV(elasticnet, parameters,cv=5)\n",
        "# Fit the Algorithm\n",
        "elastic_regressor.fit(X_train1, y_train1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JN5J2yVyZIdX"
      },
      "outputs": [],
      "source": [
        "print(\"The best fit alpha value is found out to be :\" ,elastic_regressor.best_params_)\n",
        "print(\"\\nUsing \",elastic_regressor.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmispYSrZIdY"
      },
      "outputs": [],
      "source": [
        "#model prediction\n",
        "y_pred_elastic = elastic_regressor.predict(X_test1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sUsJr-xZIdY"
      },
      "outputs": [],
      "source": [
        "# Model score on Train and Test\n",
        "train_model_enh = elastic_regressor.score(X_train1,y_train1)\n",
        "print('Training Accuracy:',train_model_enh)\n",
        "\n",
        "test_model_enh = elastic_regressor.score(X_test1,y_test1)\n",
        "print('Testing Accuracy:',test_model_enh)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ml2mPN_jZIdY"
      },
      "outputs": [],
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "MSE=mean_squared_error(y_test1,y_pred_elastic)\n",
        "print('MSE is:',MSE)\n",
        "MAE=mean_absolute_error(y_test1,y_pred_elastic)\n",
        "print('MAE is:',MAE)\n",
        "r2=r2_score(y_test1,y_pred_elastic)\n",
        "print('r2:',r2)\n",
        "adjusted_r2=(1-(1-r2_score(y_test1, y_pred_elastic))*((X_test1.shape[0]-1)/(X_test1.shape[0]-X_test1.shape[1]-1)))\n",
        "print('adjust_r2 is:',adjusted_r2)\n",
        "RMSE=math.sqrt(mean_squared_error(y_test1, y_pred_elastic))\n",
        "print('RMSE is:',RMSE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oQwySjVZIdY"
      },
      "source": [
        "### ML Model - Decision tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYtWl4m1ZIdY"
      },
      "outputs": [],
      "source": [
        "decision_tree_data = dj.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WpO-d5tNZIdY"
      },
      "outputs": [],
      "source": [
        "# multicollinearity does not affect Tree based model so we will include distance and time take.\n",
        "unnecessary_cols = ['ride_id','number_of_ticket','date',\"travel_date\",'max_capacity']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1L1NY9bZIdY"
      },
      "outputs": [],
      "source": [
        "# creating dependent and independant variable.\n",
        "x= decision_tree_data.drop(unnecessary_cols, axis=1)\n",
        "Y= decision_tree_data['number_of_ticket']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAha0iehZIdY"
      },
      "outputs": [],
      "source": [
        "#train and test split\n",
        "X_train , X_test, y_train, y_test = train_test_split(x,Y, test_size= 0.3, random_state=0 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8-6Y7WvZIdY"
      },
      "outputs": [],
      "source": [
        "#importing the library\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "# fitting decision tree model\n",
        "tree_model = DecisionTreeRegressor( criterion='squared_error', max_leaf_nodes=30,max_depth= 30,random_state=0)\n",
        "tree_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjPobZQFZIdY"
      },
      "outputs": [],
      "source": [
        "#predicting\n",
        "y_pred_tr = tree_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcabeOO7ZIdY"
      },
      "outputs": [],
      "source": [
        "# Model score on Train and Test\n",
        "train_model_tr = tree_model.score(X_train,y_train)\n",
        "print('Training Accuracy:',train_model_tr)\n",
        "\n",
        "test_model_tr = tree_model.score(X_test,y_test)\n",
        "print('Testing Accuracy:',test_model_tr)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlg5ZvoPZIdY"
      },
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkIDwRWfZIdZ"
      },
      "outputs": [],
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "MSE=mean_squared_error(y_test,y_pred_tr)\n",
        "print('MSE is:',MSE)\n",
        "MAE=mean_absolute_error(y_test,y_pred_tr)\n",
        "print('MAE is:',MAE)\n",
        "r2=r2_score(y_test,y_pred_tr)\n",
        "print('r2:',r2)\n",
        "adjusted_r2=(1-(1-r2_score(y_test, y_pred_tr))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))\n",
        "print('adjust_r2 is:',adjusted_r2)\n",
        "RMSE=math.sqrt(mean_squared_error(y_test, y_pred_tr))\n",
        "print('RMSE is:',RMSE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlJerdMCZIdZ"
      },
      "source": [
        "we not able to get good scores so far lets try `\"Ensembles method\"`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "se6-0vRDZIdZ"
      },
      "source": [
        "### ML Model - Random forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_D5SgnfZIdZ"
      },
      "outputs": [],
      "source": [
        "#importing the library\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "#initiate the model\n",
        "random_reg = RandomForestRegressor(criterion='squared_error',\n",
        " max_depth= 670,\n",
        " max_features= 'log2',\n",
        " min_samples_leaf= 6,\n",
        " min_samples_split= 5,\n",
        " n_estimators= 500)\n",
        "\n",
        "#fit the model\n",
        "random_reg.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFk3b1FvZIdZ"
      },
      "outputs": [],
      "source": [
        "#prediction\n",
        "y_pred_rf = random_reg.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdN4iRLHZIdZ"
      },
      "outputs": [],
      "source": [
        "# Model score on Train and Test\n",
        "train_model_rf = random_reg.score(X_train,y_train)\n",
        "print('Training Accuracy:',train_model_rf)\n",
        "\n",
        "test_model_rf = random_reg.score(X_test,y_test)\n",
        "print('Testing Accuracy:',test_model_rf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGEXBwysZIdZ"
      },
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XN_A2bmpZIdZ"
      },
      "outputs": [],
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "MSE=mean_squared_error(y_test,y_pred_rf)\n",
        "print('MSE is:',MSE)\n",
        "MAE=mean_absolute_error(y_test,y_pred_rf)\n",
        "print('MAE is:',MAE)\n",
        "r2=r2_score(y_test,y_pred_rf)\n",
        "print('r2:',r2)\n",
        "adjusted_r2=(1-(1-r2_score(y_test, y_pred_rf))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))\n",
        "print('adjust_r2 is:',adjusted_r2)\n",
        "RMSE=math.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
        "print('RMSE is:',RMSE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf6JZ74fZIdZ"
      },
      "source": [
        "as we saw the accuracy of train and test data, we say that Our model seem to overfit lets do hyperperemeter tuning using GridSearchCV."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaN-M8Z_ZIdZ"
      },
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYVABgkwZIdZ"
      },
      "outputs": [],
      "source": [
        "random_grid ={'criterion': ['squared_error'],\n",
        " 'max_depth':[655,660,670],\n",
        " 'max_features': ['log2'],\n",
        " 'min_samples_leaf':[6],\n",
        " 'min_samples_split': [5],\n",
        " 'n_estimators': [500,550,650]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPNRejxXZIdZ"
      },
      "outputs": [],
      "source": [
        "estimator = RandomForestRegressor()\n",
        "grid = GridSearchCV( estimator=estimator, param_grid =random_grid, cv=3, verbose=1\n",
        "                               ,n_jobs=-1 )\n",
        "grid.fit(x,Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YH6sRl0-ZIdc"
      },
      "outputs": [],
      "source": [
        "grid.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W43PUVkxZIdd"
      },
      "outputs": [],
      "source": [
        "#model prediction\n",
        "y_pred_rfh = grid.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-zSUOIiZIdd"
      },
      "outputs": [],
      "source": [
        "# Model score on Train and Test\n",
        "train_model_rfh = grid.score(X_train,y_train)\n",
        "print('Training Accuracy:',train_model_rfh)\n",
        "\n",
        "test_model_rfh = grid.score(X_test,y_test)\n",
        "print('Testing Accuracy:',test_model_rfh)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxkTXs-dZIdd"
      },
      "outputs": [],
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "MSE=mean_squared_error(y_test,y_pred_rfh)\n",
        "print('MSE is:',MSE)\n",
        "MAE=mean_absolute_error(y_test,y_pred_rfh)\n",
        "print('MAE is:',MAE)\n",
        "r2=r2_score(y_test,y_pred_rfh)\n",
        "print('r2:',r2)\n",
        "adjusted_r2=(1-(1-r2_score(y_test, y_pred_rfh))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))\n",
        "print('adjust_r2 is:',adjusted_r2)\n",
        "RMSE=math.sqrt(mean_squared_error(y_test, y_pred_rfh))\n",
        "print('RMSE is:',RMSE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4XxhMbXZIde"
      },
      "source": [
        "### Random Forest Important Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRWiIMyMZIde"
      },
      "outputs": [],
      "source": [
        "# array of important features\n",
        "importance = grid.best_estimator_.feature_importances_\n",
        "importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSOJGbeUZIde"
      },
      "outputs": [],
      "source": [
        "# plotting important features using Xgboost in built function.\n",
        "plt.figure(figsize=(12,10))\n",
        "sorted_idx = grid.best_estimator_.feature_importances_.argsort()\n",
        "plt.barh(x.columns[sorted_idx],importance[sorted_idx])\n",
        "plt.xlabel('Random Forest Feature Importance')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-hykwinpx6N"
      },
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzVzZC6opx6N"
      },
      "source": [
        "yes, as ensamples technique it giving some imporment where `Training Accuracy: 0.660359610245961`\n",
        "`Testing Accuracy: 0.5984895827012413`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65on6XKrZIde"
      },
      "source": [
        "### ML Model - XGboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBPxuYlHZIde"
      },
      "outputs": [],
      "source": [
        "#import the model\n",
        "import xgboost as xgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb5SVActZIde"
      },
      "outputs": [],
      "source": [
        "xgb_reg = xgb.XGBRegressor( booster= 'gbtree',\n",
        "                        eta= 0.004,\n",
        "                        learning_rate= 0.1,\n",
        "                        max_depth= 7,\n",
        "                        min_child_weight= 10,\n",
        "                        n_jobs= 1,\n",
        "                        objective= 'reg:linear',\n",
        "                        random_state= 0,\n",
        "                        scale_pos_weight= 1,\n",
        "                        verbosity= 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nj6diFpDZIde"
      },
      "outputs": [],
      "source": [
        "xgb_reg.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0rfjgafZIdf"
      },
      "outputs": [],
      "source": [
        "#model prediction\n",
        "y_pred_xgb = xgb_reg.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRn8aEdsZIdf"
      },
      "outputs": [],
      "source": [
        "# Model score on Train and Test\n",
        "train_model_xgb = xgb_reg.score(X_train,y_train)\n",
        "print('Training Accuracy:',train_model_xgb)\n",
        "\n",
        "test_model_xgb = xgb_reg.score(X_test,y_test)\n",
        "print('Testing Accuracy:',test_model_xgb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6S0lekCfZIdf"
      },
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3foqH3xfZIdg"
      },
      "outputs": [],
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "MSE=mean_squared_error(y_test,y_pred_xgb)\n",
        "print('MSE is:',MSE)\n",
        "MAE=mean_absolute_error(y_test,y_pred_xgb)\n",
        "print('MAE is:',MAE)\n",
        "r2=r2_score(y_test,y_pred_xgb)\n",
        "print('r2:',r2)\n",
        "adjusted_r2=(1-(1-r2_score(y_test, y_pred_xgb))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))\n",
        "print('adjust_r2 is:',adjusted_r2)\n",
        "RMSE=math.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
        "print('RMSE is:',RMSE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOJzPFjwZIdg"
      },
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLB--QhRZIdg"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZBArtf1ZIdg"
      },
      "outputs": [],
      "source": [
        "xgb = xgb.XGBRegressor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7K5Sa5x0ZIdg"
      },
      "outputs": [],
      "source": [
        "params = {\"min_child_weight\":[9,10,11],\n",
        "          'eta': [0.05,0.06,0.07],\n",
        "          'eval_metric':['rmse'],\n",
        "          'colsample_bytree':[0.6],\n",
        "          'max_depth': [8,9,10],\n",
        "          }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MvkwartZIdh"
      },
      "outputs": [],
      "source": [
        "xgb_grid = GridSearchCV(xgb,param_grid=params, verbose=1,cv=5)\n",
        "xgb_grid.fit(x, Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbxfdKgmZIdh"
      },
      "outputs": [],
      "source": [
        "xgb_grid.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgyFqKS0ZIdh"
      },
      "outputs": [],
      "source": [
        "xgb_grid.best_estimator_.get_params()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQdWirJkZIdh"
      },
      "outputs": [],
      "source": [
        "y_pred_xgbh = xgb_grid.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WsNVIzqcZIdh"
      },
      "outputs": [],
      "source": [
        "# Model score on Train and Test\n",
        "train_model_xgh = xgb_grid.score(X_train,y_train)\n",
        "print('Training Accuracy:',train_model_xgh)\n",
        "\n",
        "test_model_xgh = xgb_grid.score(X_test,y_test)\n",
        "print('Testing Accuracy:',test_model_xgh)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MV5yTqA7ZIdi"
      },
      "outputs": [],
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "MSE=mean_squared_error(y_test,y_pred_xgbh)\n",
        "print('MSE is:',MSE)\n",
        "MAE=mean_absolute_error(y_test,y_pred_xgbh)\n",
        "print('MAE is:',MAE)\n",
        "r2=r2_score(y_test,y_pred_xgbh)\n",
        "print('r2:',r2)\n",
        "adjusted_r2=(1-(1-r2_score(y_test, y_pred_xgbh))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))\n",
        "print('adjust_r2 is:',adjusted_r2)\n",
        "RMSE=math.sqrt(mean_squared_error(y_test, y_pred_xgbh))\n",
        "print('RMSE is:',RMSE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaABel6GZIdi"
      },
      "source": [
        "### XGBregressor Important Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhMgBmleZIdi"
      },
      "outputs": [],
      "source": [
        "# arry of important features\n",
        "importance = xgb_grid.best_estimator_.feature_importances_\n",
        "importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6pJ83uRZIdi"
      },
      "outputs": [],
      "source": [
        "# plotting important features using Xgboost in built function.\n",
        "plt.figure(figsize=(12,10))\n",
        "sorted_idx = xgb_grid.best_estimator_.feature_importances_.argsort()\n",
        "plt.barh(x.columns[sorted_idx],importance[sorted_idx])\n",
        "plt.xlabel('Xgboost Feature Importance')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuIIxTvHZIdj"
      },
      "source": [
        "# **Evaluating all models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRxRfGWdZIdj"
      },
      "outputs": [],
      "source": [
        "#evaluation metrics for all classifiers\n",
        "Model = [\"Linear Regression\",\"Lasso Regression\",\"Ridge Regression\",\"Elastic Net Regression\",\"Decision Tree\",'Random Forest','Xgboost']\n",
        "Train_Accuracy= [train_acc,train_model_lrh,train_model_rrh,train_model_enh,train_model_tr,train_model_rfh, train_model_xgh]\n",
        "Test_Accuracy = [test_acc,test_model_lrh,test_model_rrh,test_model_enh,test_model_tr, test_model_rfh, test_model_xgh]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8438YccpZIdj"
      },
      "outputs": [],
      "source": [
        "#creating dataframe for all classifiers using dictionary\n",
        "pd.DataFrame({\"Model\":Model,\"Train Accuracy\":Train_Accuracy,'Test Accuracy': Test_Accuracy,\n",
        "  'r2_score':[0.41873,0.41793,0.41656,0.41779,0.56849, 0.69950,0.75580],\n",
        "   'Adjusted r2_score':[0.40686,0.40604,0.40465,0.40590,0.56171,0.69477,0.751965],\n",
        "    'MSE':[50.7155, 50.78563,50.90495,50.79781,32.57962,22.68822,18.43735],\n",
        "    'RMSE':[7.12148,7.12640,7.1347,7.12725,5.70785,4.76321,4.29387],\n",
        "    'MAE':[4.8109, 4.82053,4.830123,4.82111,3.92137,3.25018,2.9953]\n",
        "             })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwLAVo9jZIdj"
      },
      "source": [
        "\n",
        "Observation:\n",
        "\n",
        "We can see from above table that\n",
        "\n",
        "1) Xgboost have highest Training and Testing Accuracy.\n",
        "\n",
        "2) Xgboost also have best r2 score.\n",
        "\n",
        "3) It also have minimum MSE, RMSE, MAE errors.\n",
        "\n",
        "Hence we can say that Xgboost is the best Model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCX9965dhzqZ"
      },
      "source": [
        "# **Conclusion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      },
      "source": [
        "1.    **As we have implemented six different models to predict the number of seats that Mobiticket can expect to sell for each ride. Linear Regression, Regularized linear regression (Ridge and Lasso), Decision Tree, Random Forest Regressor and Xgboost Regressor.\n",
        "Xgboost regression model with hyperparameter tuning performed the best among them.**\n",
        "2.    **Our Model will help Mobiticket and Bus operators to anticipate the number of tickets they can expect to sell for each ride.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5X3lPUuZIdk"
      },
      "source": [
        "***Thank you:)***"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GG8IpiCrbgKG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "y-Ehk30pYrdP",
        "Yfr_Vlr8HBkt",
        "HAih1iBOpsJ2"
      ],
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}